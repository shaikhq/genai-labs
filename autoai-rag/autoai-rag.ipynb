{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically Building a RAG Pattern Using Watsonx.ai AutoAI RAG Chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following Python notebook, I have built a **Retrieval-Augmented Generation (RAG) pipeline** to answer questions based on a collection of articles Iâ€™ve written about **IBM Db2â€™s machine learning features**.\n",
    "\n",
    "To construct this pipeline, I used **AutoAI RAG**, an automated tool available as a service on **Watsonx.ai Cloud**. AutoAI RAG simplifies the process of building an **end-to-end RAG pipeline** by running experiments with multiple configurations to identify the best-performing RAG pattern.\n",
    "\n",
    "## How AutoAI RAG Works\n",
    "\n",
    "1. **Generates candidate patterns**  \n",
    "   - Explores different **LLMs, embedding models, and retrieval strategies**.  \n",
    "2. **Evaluates candidate patterns**  \n",
    "   - Uses **sample question-answer pairs** to rank the candidates based on a predefined evaluation metric.  \n",
    "3. **Automates complexity**  \n",
    "   - Removes the need for manual design and optimization.  \n",
    "4. **Deploys the best pattern**  \n",
    "   - Once the optimal pattern is found, it is automatically deployed on **Watsonx.ai**, enabling seamless **question-answering** over a **private knowledge base**.\n",
    "\n",
    "This automation makes it significantly easier to build and deploy **accurate RAG pipelines** without dealing with the underlying complexities.\n",
    "\n",
    "Check it out!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prerequisites**  \n",
    "\n",
    "Before running this notebook, ensure that you have:  \n",
    "\n",
    "### **1. Set Up a Python Environment**  \n",
    "- Create a Python environment with the required dependencies.  \n",
    "- This notebook was developed using **Python 3.12.3** within a **virtual environment (venv)**.  \n",
    "- The complete list of installed Python packages and their versions is available in the **[`requirements.txt`](requirements.txt\n",
    ")** file located in the same directory of this notebook.  \n",
    "\n",
    "### **2. Provision Watsonx.ai Runtime and Create a Watsonx.ai Project**  \n",
    "- You need an active **Watsonx.ai runtime** and a **Watsonx.ai project**.  \n",
    "- Follow the instructions in the official documentation:  \n",
    "  ðŸ‘‰ [Coding an AutoAI RAG experiment with a Chroma vector store](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-rag-code-chroma.html?context=wx&audience=wdp)  \n",
    "\n",
    "### **3. Configure API Credentials**  \n",
    "- In the same directory as this notebook, create a file named **`.env`** (the filename must be exactly `.env`).  \n",
    "- Add the following keys and replace the placeholders with your actual credentials:  \n",
    "\n",
    "```ini\n",
    "WATSONX_PROJECT=REPLACE_WITH_YOUR_WATSONX_AI_PROJECT_ID\n",
    "WATSONX_APIKEY=REPLACE_WITH_YOUR_WATSONX_AI_RUNTIME_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `watsonx.ai` APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `watsonx.ai` API key and project id from `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(os.getcwd()+\"/.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `watsonx.ai` credentials and create an instance of `watsonx.ai` APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "                url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "                api_key = os.getenv(\"WATSONX_APIKEY\", \"\")\n",
    "                )\n",
    "\n",
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the watsonx.ai `project id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = os.getenv(\"WATSONX_PROJECT\", \"\")\n",
    "client.set.default_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Upload Training Data to IBM Cloud COS bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the list of files that I previously uploaded to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ASSET_TYPE</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>ASSET_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ModelInference.txt</td>\n",
       "      <td>data_asset</td>\n",
       "      <td>20198</td>\n",
       "      <td>56345f72-6f01-41b3-8e8c-bbd31011c164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benchmarking_data_ModelInference.json</td>\n",
       "      <td>data_asset</td>\n",
       "      <td>458</td>\n",
       "      <td>cfe2836e-cebf-4c59-8c99-d042c7418021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    NAME  ASSET_TYPE   SIZE  \\\n",
       "0                     ModelInference.txt  data_asset  20198   \n",
       "1  benchmarking_data_ModelInference.json  data_asset    458   \n",
       "\n",
       "                               ASSET_ID  \n",
       "0  56345f72-6f01-41b3-8e8c-bbd31011c164  \n",
       "1  cfe2836e-cebf-4c59-8c99-d042c7418021  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.data_assets.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training content from the above URL and save it locally as `ModelInference.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html\"\n",
    "\n",
    "docs = WebBaseLoader(url).load()\n",
    "\n",
    "# Access the content of the loaded document\n",
    "train_doc_content = docs[0].page_content\n",
    "train_filename = \"ModelInference.txt\"\n",
    "\n",
    "with open(train_filename, \"w\") as file:\n",
    "        # Write the content of the web page to the file\n",
    "        file.write(train_doc_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ModelInference.txt` wasnt's previously uploaded to COS, Upload it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file: ModelInference.txt was previously uploaded with asset ID: 56345f72-6f01-41b3-8e8c-bbd31011c164\n"
     ]
    }
   ],
   "source": [
    "wx_assets = client.data_assets.list()\n",
    "\n",
    "# If an asset with the name document_file doesn't exist already, upload it to wx.ai\n",
    "if train_filename not in wx_assets['NAME'].values:\n",
    "    # Upload the training file\n",
    "    document_asset_details = client.data_assets.create(name=train_filename, file_path=train_filename)\n",
    "    print(f'Uploaded training file: {train_filename}')\n",
    "    \n",
    "    # Get the ID of the uploaded training file\n",
    "    document_asset_id = client.data_assets.get_id(document_asset_details)\n",
    "    \n",
    "    # Define a connection to the training data\n",
    "    train_data_references = [DataConnection(data_asset_id=document_asset_id)]\n",
    "else:\n",
    "    # Get the asset_id for the matching row\n",
    "    document_asset_id = wx_assets.loc[wx_assets['NAME'] == train_filename, 'ASSET_ID'].iloc[0]\n",
    "    print(f\"Training file: {train_filename} was previously uploaded with asset ID: {document_asset_id}\")\n",
    "    \n",
    "    # Define a connection to the previously uploaded training data\n",
    "    train_data_references = [DataConnection(data_asset_id=document_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Upload Evaluation data to COS \n",
    "`AutoAI RAG` experiment will use this evaluation data to compute the accuracy of candidate `RAG Pipelines` during the exeriment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'benchmarking_data_ModelInference.json' has been overwritten successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "benchmarking_data_IBM_page_content = [\n",
    "    {\n",
    "        \"question\": \"What is path to ModelInference class?\",\n",
    "        \"correct_answer\": \"ibm_watsonx_ai.foundation_models.inference.ModelInference\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"ModelInference.txt\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is method for get model inferance details?\",\n",
    "        \"correct_answer\": \"get_details()\",\n",
    "        \"correct_answer_document_ids\": [\n",
    "            \"ModelInference.txt\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "test_filename = \"benchmarking_data_ModelInference.json\"\n",
    "\n",
    "# Overwrite the file regardless of its existence\n",
    "with open(test_filename, \"w\") as json_file:\n",
    "    json.dump(benchmarking_data_IBM_page_content, json_file, indent=4)\n",
    "    print(f\"File '{test_filename}' has been overwritten successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an asset with the name test_filename doesn't exist already, upload it to wx.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file: benchmarking_data_ModelInference.json was previously uploaded with asset ID: cfe2836e-cebf-4c59-8c99-d042c7418021\n"
     ]
    }
   ],
   "source": [
    "if test_filename not in wx_assets['NAME'].values:\n",
    "    # Upload the test file\n",
    "    document_asset_details = client.data_assets.create(name=test_filename, file_path=test_filename)\n",
    "    print(f'Uploaded test file: {test_filename}')\n",
    "    \n",
    "    # Get the ID of the uploaded test file\n",
    "    document_asset_id = client.data_assets.get_id(document_asset_details)\n",
    "    \n",
    "    # Define a connection to the test data\n",
    "    test_data_references = [DataConnection(data_asset_id=document_asset_id)]\n",
    "else:\n",
    "    # Get the asset_id for the matching row\n",
    "    document_asset_id = wx_assets.loc[wx_assets['NAME'] == test_filename, 'ASSET_ID'].iloc[0]\n",
    "    print(f\"Test file: {test_filename} was previously uploaded with asset ID: {document_asset_id}\")\n",
    "    \n",
    "    # Define a connection to the previously uploaded test data\n",
    "    test_data_references = [DataConnection(data_asset_id=document_asset_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Run `AutoAI RAG` Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = AutoAI(credentials, project_id=project_id)\n",
    "rag_optimizer_name = 'DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the list of Past `AutoAI RAG` experiment runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>run_id</th>\n",
       "      <th>state</th>\n",
       "      <th>auto_pipeline_optimizer name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-16T16:17:16.389Z</td>\n",
       "      <td>596ddb0f-1bbc-492b-bec5-0a0b4f7bc599</td>\n",
       "      <td>completed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-14T19:46:53.187Z</td>\n",
       "      <td>98804827-00b4-4a08-af0a-38912903bab1</td>\n",
       "      <td>completed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-14T17:27:17.666Z</td>\n",
       "      <td>a23c7ab2-903b-4cf8-92f6-a20986d74099</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-14T16:18:52.696Z</td>\n",
       "      <td>ab3277bb-fe33-417d-b8ea-3b70c0744f2c</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-14T15:59:55.175Z</td>\n",
       "      <td>4145dd5f-94da-425c-85b6-b00e24971cd5</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-14T15:50:56.139Z</td>\n",
       "      <td>85a2cab9-e863-412b-895b-daaebd2fd29d</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-14T14:45:58.774Z</td>\n",
       "      <td>2ec7c054-970d-48e8-bdce-d5ecb91dbbae</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-10T21:26:42.846Z</td>\n",
       "      <td>46f9ac00-3896-419f-97db-6c06b6fd1965</td>\n",
       "      <td>failed</td>\n",
       "      <td>DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                                run_id      state  \\\n",
       "0  2025-01-16T16:17:16.389Z  596ddb0f-1bbc-492b-bec5-0a0b4f7bc599  completed   \n",
       "1  2025-01-14T19:46:53.187Z  98804827-00b4-4a08-af0a-38912903bab1  completed   \n",
       "2  2025-01-14T17:27:17.666Z  a23c7ab2-903b-4cf8-92f6-a20986d74099     failed   \n",
       "3  2025-01-14T16:18:52.696Z  ab3277bb-fe33-417d-b8ea-3b70c0744f2c     failed   \n",
       "4  2025-01-14T15:59:55.175Z  4145dd5f-94da-425c-85b6-b00e24971cd5     failed   \n",
       "5  2025-01-14T15:50:56.139Z  85a2cab9-e863-412b-895b-daaebd2fd29d     failed   \n",
       "6  2025-01-14T14:45:58.774Z  2ec7c054-970d-48e8-bdce-d5ecb91dbbae     failed   \n",
       "7  2025-01-10T21:26:42.846Z  46f9ac00-3896-419f-97db-6c06b6fd1965     failed   \n",
       "\n",
       "                        auto_pipeline_optimizer name  \n",
       "0  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "1  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "2  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "3  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "4  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "5  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "6  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  \n",
       "7  DEMO - AutoAI RAG ibm-watsonx-ai SDK documenta...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_experiments = experiment.runs(filter='rag_optimizer').list()\n",
    "past_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the list of past `AutoAI RAG` experiment runs includes a successful run of the `DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation` rag optimizer. \n",
    "- If a successful run is found, load this run from history. \n",
    "- If no successful run of the given rag optimizer is found, then start a new run of this rag optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving previously created RAG Optimizer: DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation, runid: 596ddb0f-1bbc-492b-bec5-0a0b4f7bc599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the timestamp column is in datetime format\n",
    "past_experiments['timestamp'] = pd.to_datetime(past_experiments['timestamp'])\n",
    "\n",
    "# Filter for rows matching the given optimizer name and not in failed state\n",
    "filtered_experiments = past_experiments[\n",
    "    (past_experiments['auto_pipeline_optimizer name'] == rag_optimizer_name) &\n",
    "    (past_experiments['state'] != 'failed')\n",
    "]\n",
    "\n",
    "if filtered_experiments.empty:\n",
    "    print(f\"No runs found for optimizer '{rag_optimizer_name}' in a non-failed state.\")\n",
    "    \n",
    "    print(f'create and run a new RAG Optimizer: {rag_optimizer_name}')\n",
    "    # create a new experiment\n",
    "    rag_optimizer = experiment.rag_optimizer(\n",
    "        name=rag_optimizer_name,\n",
    "        description=\"AutoAI RAG Optimizer for Db2 AI Blogs\",\n",
    "        max_number_of_rag_patterns=4,\n",
    "        optimization_metrics=[AutoAI.RAGMetrics.ANSWER_CORRECTNESS]\n",
    "    )\n",
    "    \n",
    "    rag_optimizer.run(\n",
    "        input_data_references=train_data_references,\n",
    "        test_data_references=test_data_references,\n",
    "        background_mode=False\n",
    "    )\n",
    "    \n",
    "    print(f'status of RAG Optimizer: {rag_optimizer_name} is {rag_optimizer.get_run_status()}')\n",
    "else:\n",
    "    # Sort the filtered dataframe by timestamp in descending order\n",
    "    sorted_experiments = filtered_experiments.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "    # Get the run_id of the most recent run\n",
    "    most_recent_run_id = sorted_experiments.iloc[0]['run_id']\n",
    "        \n",
    "     # get the previously completed experiment with the same name as experiment_name\n",
    "    print(f'Retrieving previously created RAG Optimizer: {rag_optimizer_name}, runid: {most_recent_run_id}')\n",
    "    \n",
    "     # Get the historical rag_optimizer instance and training details\n",
    "    rag_optimizer = experiment.runs.get_rag_optimizer(most_recent_run_id)\n",
    "\n",
    "summary = rag_optimizer.summary(scoring=\"faithfulness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the list of `RAG patterns` from the successful run of rag optimizer: `DEMO - AutoAI RAG ibm-watsonx-ai SDK documentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_faithfulness</th>\n",
       "      <th>mean_answer_correctness</th>\n",
       "      <th>mean_context_correctness</th>\n",
       "      <th>chunking.method</th>\n",
       "      <th>chunking.chunk_size</th>\n",
       "      <th>chunking.chunk_overlap</th>\n",
       "      <th>embeddings.model_id</th>\n",
       "      <th>vector_store.distance_metric</th>\n",
       "      <th>retrieval.method</th>\n",
       "      <th>retrieval.number_of_chunks</th>\n",
       "      <th>generation.model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pattern2</th>\n",
       "      <td>0.8654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-1-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern5</th>\n",
       "      <td>0.8281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>cosine</td>\n",
       "      <td>window</td>\n",
       "      <td>3</td>\n",
       "      <td>meta-llama/llama-3-1-8b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern4</th>\n",
       "      <td>0.8182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>cosine</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern1</th>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>ibm/slate-125m-english-rtrvr</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>window</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pattern3</th>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>recursive</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>simple</td>\n",
       "      <td>5</td>\n",
       "      <td>meta-llama/llama-3-1-70b-instruct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean_faithfulness  mean_answer_correctness  \\\n",
       "Pattern_Name                                               \n",
       "Pattern2                 0.8654                      1.0   \n",
       "Pattern5                 0.8281                      1.0   \n",
       "Pattern4                 0.8182                      1.0   \n",
       "Pattern1                 0.5216                      0.5   \n",
       "Pattern3                 0.1837                      0.5   \n",
       "\n",
       "              mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
       "Pattern_Name                                                                  \n",
       "Pattern2                           1.0       recursive                 1024   \n",
       "Pattern5                           1.0       recursive                 1024   \n",
       "Pattern4                           1.0       recursive                 1024   \n",
       "Pattern1                           1.0       recursive                  512   \n",
       "Pattern3                           1.0       recursive                 1024   \n",
       "\n",
       "              chunking.chunk_overlap             embeddings.model_id  \\\n",
       "Pattern_Name                                                           \n",
       "Pattern2                         256  intfloat/multilingual-e5-large   \n",
       "Pattern5                         512  intfloat/multilingual-e5-large   \n",
       "Pattern4                         256  intfloat/multilingual-e5-large   \n",
       "Pattern1                         256    ibm/slate-125m-english-rtrvr   \n",
       "Pattern3                         256  intfloat/multilingual-e5-large   \n",
       "\n",
       "             vector_store.distance_metric retrieval.method  \\\n",
       "Pattern_Name                                                 \n",
       "Pattern2                        euclidean           window   \n",
       "Pattern5                           cosine           window   \n",
       "Pattern4                           cosine           window   \n",
       "Pattern1                        euclidean           window   \n",
       "Pattern3                        euclidean           simple   \n",
       "\n",
       "              retrieval.number_of_chunks                generation.model_id  \n",
       "Pattern_Name                                                                 \n",
       "Pattern2                               5  meta-llama/llama-3-1-70b-instruct  \n",
       "Pattern5                               3   meta-llama/llama-3-1-8b-instruct  \n",
       "Pattern4                               5    meta-llama/llama-3-70b-instruct  \n",
       "Pattern1                               5    meta-llama/llama-3-70b-instruct  \n",
       "Pattern3                               5  meta-llama/llama-3-1-70b-instruct  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the details of the best `RAG` pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pattern is: Pattern2\n",
      "mean_faithfulness                                          0.8654\n",
      "mean_answer_correctness                                       1.0\n",
      "mean_context_correctness                                      1.0\n",
      "chunking.method                                         recursive\n",
      "chunking.chunk_size                                          1024\n",
      "chunking.chunk_overlap                                        256\n",
      "embeddings.model_id                intfloat/multilingual-e5-large\n",
      "vector_store.distance_metric                            euclidean\n",
      "retrieval.method                                           window\n",
      "retrieval.number_of_chunks                                      5\n",
      "generation.model_id             meta-llama/llama-3-1-70b-instruct\n",
      "Name: Pattern2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_pattern_name = summary.index.values[0]\n",
    "print('Best pattern is:', best_pattern_name)\n",
    "\n",
    "print(summary.loc[best_pattern_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the best pattern from the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these three lines swap the stdlib sqlite3 lib with the pysqlite3 package\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46.1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "print(sqlite3.sqlite_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaikhq/genai-lab/.venv/lib64/python3.12/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:416: LifecycleWarning: Model 'meta-llama/llama-3-1-70b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-3-70b-instruct, llama-3-2-90b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warnings.warn(\n",
      "/home/shaikhq/genai-lab/.venv/lib64/python3.12/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:416: LifecycleWarning: Model 'meta-llama/llama-3-1-70b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-3-70b-instruct, llama-3-2-90b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_pattern = rag_optimizer.get_pattern(pattern_name=best_pattern_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.34.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Vector Index Using the best pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download My 3 articles, chunk and vectorize them using the best `RAG` pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://community.ibm.com/community/user/datamanagement/blogs/shaikh-quader/2024/05/07/building-an-in-db-linear-regression-model-with-ibm\",\n",
    "    \"https://www.ibm.com/blog/how-to-build-a-decision-tree-model-in-ibm-db2/\",\n",
    "    \"https://community.ibm.com/community/user/datamanagement/blogs/shaikh-quader/2024/05/27/db2ai-pyudf\"\n",
    "]\n",
    "docs_list = WebBaseLoader(urls).load()\n",
    "doc_splits = best_pattern.chunker.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of chunks created from the above 3 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an in-memory vector index, using the above chunks, with `Chromadb` and the best rag pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pattern.indexing_function(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask Questions from Indexed Articles Using the Best RAG Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First Question`: How to generate summary statistics for a Db2 table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How to generate summary statistics for a Db2 table?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Second Question`: `How can one inference a Python model with Db2?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How can one inference a Python model with Db2?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Third Question`: `How to integrate a Python model with Db2?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How to integrate a Python model with Db2?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fourth Question`: `What is Python UDF?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What is Python UDF?\"]\n",
    "\n",
    "payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"values\": questions,\n",
    "            \"access_token\": client.service_instance._get_token()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_response = best_pattern.inference_function()(payload)\n",
    "Markdown(score_response[\"predictions\"][0][\"values\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Automating a RAG pattern with AutoAI (watxonx doc)](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-programming-rag.html?context=wx)\n",
    "2. [AutoAI RAG Sample Notebooks (Github)](https://github.com/IBM/watson-machine-learning-samples/tree/master/cloud/notebooks/python_sdk/experiments/autoai_rag)\n",
    "3. [AutoAI Python SDK](https://ibm.github.io/watsonx-ai-python-sdk/autoai.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
